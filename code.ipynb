{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73460083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ab9c8b",
   "metadata": {},
   "source": [
    "# Text Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bec31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize, sent_tokenize\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import gutenbergpy.textget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c49147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/metadata_added.csv', encoding_errors='ignore')\n",
    "\n",
    "# Removing non-English works, works without year of first publication, renewed works, and works with various authors\n",
    "metadata_df = df[(df['lang'] == 'English') & (df['year'].notnull()) & \n",
    "                 (df['renewed'] == False) & (df['author_id'] != 116)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1b0bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preamble, postamble patterns\n",
    "\n",
    "foreword_pattern = r'(.|\\n)*\\*\\*\\* ?START OF(.|\\n)*?\\*\\*\\*'\n",
    "transc_pattern = r'\\[Transcriber((.|\\n)*?)\\]'\n",
    "prod_pattern = r'Produced by(.|\\n)*?\\n\\n\\n'\n",
    "prep_pattern = r'E-text prepared by(.|\\n)*?\\n\\n'\n",
    "prep_pattern2 = r'This etext was(.|\\n)*?\\n\\n'\n",
    "note_pattern = r'Note: (.|\\n)*?\\n\\n'\n",
    "illust1_pattern = r'Illustrated by.*?\\n'\n",
    "illust2_pattern = r'\\[Illust.*?\\n'\n",
    "transc_note_pattern = r'(T|t)ranscriber(.)?s? (N|n)ote(.|\\n)*?\\n\\n'\n",
    "transc_note_pattern2 = r'TRANSCRIBER\\'S NOTE(.|\\n)*?\\n\\n'\n",
    "license_pattern = r'\\*\\*\\* ?END OF(?:.|\\n)*'\n",
    "end_pattern = r'End of(.+)Gutenberg(.+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435d70ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopwords from spaCy\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50084d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bad_word(word):\n",
    "    if len(word) < 2:\n",
    "        return True\n",
    "    if not word.isalpha():\n",
    "        return True\n",
    "    if word in stop_words:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def get_bow(book_txt):\n",
    "    '''\n",
    "    input: Text of the SF novel\n",
    "    output: bag-of-words for given novel (list of str)\n",
    "    '''    \n",
    "    book_bow = []\n",
    "\n",
    "    book_txt = re.sub(foreword_pattern, \"\", book_txt, 1)\n",
    "    book_txt = re.sub(transc_pattern, \"\", book_txt, 1)\n",
    "    book_txt = re.sub(prod_pattern, \"\", book_txt, 1)\n",
    "    \n",
    "    book_txt = re.sub(illust1_pattern, \"\", book_txt, 1)\n",
    "    book_txt = re.sub(illust2_pattern, \"\", book_txt, 1)\n",
    "    book_txt = re.sub(transc_note_pattern, \"\", book_txt, 1)\n",
    "    book_txt = re.sub(transc_note_pattern2, \"\", book_txt, 1)\n",
    "    \n",
    "    book_txt = re.sub(prep_pattern, \"\", book_txt, 1)\n",
    "    book_txt = re.sub(prep_pattern2, \"\", book_txt, 1)\n",
    "    \n",
    "    book_txt = re.sub(note_pattern, \"\", book_txt, 1)\n",
    "    book_txt = re.sub(license_pattern, \"\", book_txt, 1)\n",
    "    book_txt = re.sub(end_pattern, \"\", book_txt, 1)\n",
    "\n",
    "    # removing newline character\n",
    "    book_txt = book_txt.replace('\\n', ' ')\n",
    "\n",
    "    # tokenization\n",
    "    for sent in book_txt.split('.'):\n",
    "        doc = nlp(sent)\n",
    "        # lemmatization, removing proper noun \n",
    "        sent_bow = [token.lemma_.lower() for token in doc if token.pos_ not in ['PROPN', 'NNP', 'NNPS', 'NE', 'NNE', 'NR', 'pnc']]\n",
    "        sent_bow = [w for w in sent_bow if not _bad_word(w)]\n",
    "        if len(sent_bow) > 0:\n",
    "            book_bow.append(sent_bow)\n",
    "            \n",
    "    return book_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a6c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "for book_id in tqdm(tobe_used['book_id'].tolist()):\n",
    "    \n",
    "    with open(f'./data/original/{book_id}.txt', 'r') as f:\n",
    "        book_txt = f.read()\n",
    "    f.close()\n",
    "    \n",
    "    book_bow = get_bow(book_txt)\n",
    "    \n",
    "    with open(f'./data/processed_by_sent_propn_filtered/{book_id}.txt', 'w') as f:\n",
    "        for line in book_bow:\n",
    "            f.write(' '.join(line) + '\\n')\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b31a3f",
   "metadata": {},
   "source": [
    "# Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58e69fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5986d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_bow(book_id):\n",
    "    with open(f'./data/processed_by_sent_propn_filtered/{book_id}.txt', 'r') as f:\n",
    "        bow = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "    bow = [word.strip('\\n').split(' ') for word in bow]\n",
    "    bow = [word for word in bow if len(word) > 0]\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ad8288",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "\n",
    "for book_id in metadata_df['book_id'].tolist():\n",
    "    corpus += process_bow(book_id)\n",
    "    \n",
    "model = Word2Vec(sentences=corpus, vector_size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2ae632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_vec(book_id):\n",
    "    vec = np.zeros(300)\n",
    "    bow = [item for sublist in process_bow(book_id) for item in sublist]\n",
    "    length = 0\n",
    "    \n",
    "    for word in bow:\n",
    "        try:\n",
    "            vec += model.wv[word]\n",
    "            length += 1\n",
    "        except KeyError:\n",
    "            continue\n",
    "    \n",
    "    return vec / length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63fe473",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_emb = []\n",
    "for book_id in tqdm(metadata_df['book_id'].tolist()):\n",
    "    doc_emb.append(get_doc_vec(book_id))\n",
    "    \n",
    "len(doc_emb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da78b63b",
   "metadata": {},
   "source": [
    "# Network Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10b4409",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from networkx.algorithms.components import connected_components\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f63113",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_num = len(doc_emb)\n",
    "sim_mat = np.zeros((doc_num, doc_num))\n",
    "\n",
    "for i in range(doc_num):\n",
    "    for j in range(doc_num):\n",
    "        sim_mat[i][j] = np.dot(doc_emb[i], doc_emb[j]) / (norm(doc_emb[i]) * norm(doc_emb[j]))\n",
    "        \n",
    "print(len(sim_mat))\n",
    "print(sim_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de931f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.85\n",
    "graph = nx.DiGraph()\n",
    "\n",
    "for i in range(doc_num):\n",
    "    graph.add_node(i, title=metadata_df.iloc[i]['title'], year=metadata_df.iloc[i]['year'], author=metadata_df.iloc[i]['author'], author_id=metadata_df.iloc[i]['author_id'])\n",
    "    \n",
    "for i in range(doc_num):\n",
    "    for j in range(doc_num):\n",
    "        if sim_mat[i][j] > threshold and metadata_df.iloc[i]['year'] < metadata_df.iloc[j]['year']:\n",
    "            graph.add_edge(i,j, weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fb208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_gexf(graph, './SF_network.gexf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42eb8413",
   "metadata": {},
   "source": [
    "# Author Distinctiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./author_dict.pkl', 'rb') as f:\n",
    "    author_dict = pickle.load(f)\n",
    "    \n",
    "f.close()\n",
    "\n",
    "with open('./author_id_dict.pkl', 'rb') as f:\n",
    "    author_id_dict = pickle.load(f)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cb870b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_list = []\n",
    "author_list = []\n",
    "doc_num = len(graph.nodes)\n",
    "\n",
    "for auth, auth_list in author_dict.items():\n",
    "    if len(auth_list) > 1:\n",
    "        auth_comm = [set([str(idx) for idx in auth_list])]\n",
    "        auth_comm += [{str(idx)} for idx in range(doc_num) if idx not in auth_list]\n",
    "    \n",
    "        author_list.append(auth)\n",
    "        mod_list.append(nx.community.modularity(undi_graph, auth_comm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a5179c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative probability plot\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "modified = np.add(np.multiply(mod_list, 10000), -10000*min(mod_list)+1)\n",
    "\n",
    "x = np.linspace(min(modified), max(modified), 1000)\n",
    "y = [np.sum(np.greater_equal(modified, x_val))/len(modified) for x_val in x]\n",
    "\n",
    "new_x = []\n",
    "new_y = []\n",
    "y_prev = 1\n",
    "x_prev = 1\n",
    "\n",
    "for x_elem, y_elem in zip(x, y):\n",
    "    if y_elem < y_prev:\n",
    "        new_x.append(x_elem)\n",
    "        new_y.append(y_elem)\n",
    "        y_prev = y_elem\n",
    "        x_prev = x_elem\n",
    "\n",
    "plt.vlines([1, 2, 4, 8], ymin=0, ymax=2, linestyles='dashdot', color='grey', alpha=0.6)\n",
    "plt.hlines([1, 0.1, 0.01], xmin=-5, xmax=16, linestyles='dashdot', color='grey', alpha=0.6)\n",
    "plt.xlim((0.9, 16))\n",
    "plt.ylim((0.002, 2))\n",
    "\n",
    "        \n",
    "# plt.plot(x, y, linewidth=1, color='blue')\n",
    "plt.plot(new_x, new_y, linewidth=1, color='blue', marker='o', markersize=12)\n",
    "plt.plot(new_x, new_y, linewidth=0, color='white', marker='o', markersize=7)\n",
    "plt.xscale('log', base=2)\n",
    "plt.yscale('log', base=10)\n",
    "\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xlabel(r'Distinctiveness $D$', fontsize=25, fontweight='bold')\n",
    "plt.ylabel(r'Cumulative Probability $Pr (X \\geq x)$', fontsize=25, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./distinctiveness_cumul.eps', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbb96c3",
   "metadata": {},
   "source": [
    "# Community Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a37f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "undi_graph = nx.Graph(graph)\n",
    "comm = nx.community.louvain_communities(undi_graph, seed=42)\n",
    "for i, c in enumerate(comm):\n",
    "    for node_id in c:\n",
    "        undi_graph.nodes[node_id]['community'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a916ee7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y12 = [h.get_height() for h in sns.histplot([undi_graph.nodes[nod]['year'] for nod in comm[12]], kde=False, binrange=(1870, 1970), binwidth=5).patches]\n",
    "plt.close()\n",
    "y19 = [h.get_height() for h in sns.histplot([undi_graph.nodes[nod]['year'] for nod in comm[19]], kde=False, binrange=(1870, 1970), binwidth=5).patches]\n",
    "plt.close()\n",
    "y30 = [h.get_height() for h in sns.histplot([undi_graph.nodes[nod]['year'] for nod in comm[30]], kde=False, binrange=(1870, 1970), binwidth=5).patches]\n",
    "plt.close()\n",
    "y32 = [h.get_height() for h in sns.histplot([undi_graph.nodes[nod]['year'] for nod in comm[32]], kde=False, binrange=(1870, 1970), binwidth=5).patches]\n",
    "plt.close()\n",
    "y35 = [h.get_height() for h in sns.histplot([undi_graph.nodes[nod]['year'] for nod in comm[35]], kde=False, binrange=(1870, 1970), binwidth=5).patches]\n",
    "plt.close()\n",
    "\n",
    "x = [data for data in range(1870, 1970, 5)]\n",
    "\n",
    "comm_df = pd.DataFrame(index=x, data={\n",
    "    'Community I': y12,\n",
    "    'Community II': y30,\n",
    "    'Community III': y19,\n",
    "    'Community IV': y32,\n",
    "    'Community V': y35\n",
    "})\n",
    "\n",
    "new_indices = {}\n",
    "for year in range(1870, 1970, 5):\n",
    "    new_indices[year] = f'{year}~{year+5}' \n",
    "\n",
    "comm_df.rename(index=new_indices, inplace=True)\n",
    "\n",
    "comm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759e208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference: https://stackoverflow.com/questions/41778964/using-both-log-and-stack-on-a-pandas-bar-plot\n",
    "\n",
    "d = np.zeros(comm_df.shape)\n",
    "for j in range(len(comm_df)):\n",
    "    row = comm_df.iloc[j, :]\n",
    "    g = np.zeros(len(row)+1)\n",
    "    G = np.sum(row)\n",
    "    g[1:] = np.cumsum(row)\n",
    "    f = 10**(g/G*np.log10(G))\n",
    "    f[0] = 0\n",
    "    d[j, :] = np.diff(f)\n",
    "    \n",
    "pd.DataFrame(d, index=comm_df.index, columns=comm_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4916fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(d, index=comm_df.index, columns=comm_df.columns)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(30)\n",
    "\n",
    "ax.set_xlim(1865, 1975)\n",
    "ax.set_ylim(0.999, 1000)\n",
    "ax.set_xlabel('Year', fontsize=30, fontweight='bold')\n",
    "ax.set_ylabel('The total number of works', fontsize=30, fontweight='bold')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# comm_ratio_df.plot(kind='bar', stacked=True, ax=ax, color=['red', 'blue', 'orange', 'green', 'purple'], alpha=0.8, align='center', width=0.6)\n",
    "data_df.plot(kind='bar', stacked=True, ax=ax, color=['red', 'blue', 'orange', 'green', 'purple'], alpha=0.8, align='center', width=0.6)\n",
    "plt.xticks(fontsize=25, rotation=75)\n",
    "plt.yticks(fontsize=25)\n",
    "\n",
    "ax.get_legend().remove()\n",
    "'''\n",
    "for i in range(len(d)-1):\n",
    "    for j in range(5):\n",
    "        ax.plot([i+0.3, i+0.7], [sum(data_df.iloc[i, :j+1]), sum(data_df.iloc[i+1, :j+1])], color='black', ls='--', zorder=1)\n",
    "'''\n",
    "\n",
    "ax.legend(loc='upper left', fontsize=35, ncols=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./community_ratio_stacked_log.eps', transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1ec182",
   "metadata": {},
   "source": [
    "## Prominent Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f98b4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./novel_subjects.pkl', 'rb') as f:\n",
    "    fiction_subject = pickle.load(f)\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b1ffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_df['community'] = metadata_df.apply(lambda row: undi_graph.nodes[str(row.name)]['community'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61006368",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [d for _, d in fiction_subject.items()]\n",
    "tags_set = set([x for xs in tags for x in xs])\n",
    "\n",
    "comm_sbj_matrix = pd.DataFrame(data=0, index=[d for d in range(37)], columns = list(tags_set), dtype=int)\n",
    "for book_id, comm in zip(metadata_df['book_id'].tolist(), metadata_df['community'].tolist()):\n",
    "    for elem in fiction_subject[str(book_id)]:\n",
    "        comm_sbj_matrix.loc[comm, elem] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2abd5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idf = np.log(np.divide(884, np.add(1, comm_sbj_matrix.astype(bool).sum(axis=0))))\n",
    "tag_idf = comm_sbj_matrix.mul(idf, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f704f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Community number and name\n",
    "# Community I: 12\n",
    "# Community II: 30\n",
    "# Community III: 19\n",
    "# Community IV: 32\n",
    "# Community V: 35\n",
    "\n",
    "# Top 20 prominent tags of Community II\n",
    "\n",
    "tag_idf.loc[30, :].sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef01c51c",
   "metadata": {},
   "source": [
    "## Diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed29e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_period_diversity(G, start_year, end_year):\n",
    "    comm_dict = {}\n",
    "    for nod in G.nodes:\n",
    "        if G.nodes[nod]['year'] >= start_year and G.nodes[nod]['year'] < end_year:\n",
    "            comm_dict[G.nodes[nod]['community']] = comm_dict.get(G.nodes[nod]['community'], 0) + 1\n",
    "            \n",
    "    comm_dist = np.zeros(5)\n",
    "    comm_dist[:len(comm_dict)] = list(comm_dict.values())\n",
    "    comm_dist /= np.sum(comm_dist)\n",
    "    return scipy.stats.entropy(comm_dist, base=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6659cd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "works = []\n",
    "years = []\n",
    "diversity = []\n",
    "for year in range(1810, 2000):\n",
    "    years.append(year)\n",
    "    diversity.append(get_period_diversity(undi_graph, year-5, year+5))\n",
    "    w = 0\n",
    "    for nod in undi_graph.nodes:\n",
    "        if undi_graph.nodes[nod]['year'] >= year-5 and undi_graph.nodes[nod]['year'] < year+5:\n",
    "            w += 1\n",
    "    works.append(w)\n",
    "    \n",
    "len(works)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001fca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_figheight(15)\n",
    "fig.set_figwidth(30)\n",
    "\n",
    "ax.plot(years, diversity, color='r', marker='o', linewidth=1, markersize=16)\n",
    "ax.plot(years, diversity, color='w', marker='o', linewidth=0, markersize=10)\n",
    "ax.set_xlabel('Year', fontsize=30)\n",
    "ax.set_ylabel('Diversity $H$', color='r', fontsize=30)\n",
    "ax.tick_params(axis='y', colors='red', labelsize=20)\n",
    "ax.tick_params(axis='x', labelsize=20)\n",
    "\n",
    "ax.set_xlim([1865, 1975])\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('./comm_diversity.eps', transparent=True, format='eps')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
